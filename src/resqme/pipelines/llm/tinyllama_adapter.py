"""
Auto-generated adapter to run the user's original script inside a class without modifying its logic.
The original code is embedded as a raw string and executed in an isolated namespace.
"""
from types import SimpleNamespace

class TinyLlamaScript:
    def __init__(self, extra_globals=None):
        # Extra globals can inject variables like paths if the original script expects them
        self.extra_globals = extra_globals or {}

    def run(self):
        code = r"import pandas as pd\nimport random\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom tqdm import tqdm\n\n# === CONFIG ===\nSYMPTOM_FILE = \"symptom_matrix_english_v2.csv\"\nOUTPUT_FILE = \"generated_monologues_manual_review.csv\"\nNUM_CALLS_PER_DISEASE = 3\nMODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n\n# === LOAD DATA ===\nsymptom_matrix = pd.read_csv(SYMPTOM_FILE, index_col=0)\n\n# === LOAD MODEL ===\nprint(\"\ud83d\udd04 Loading model... This may take a minute the first time.\")\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_ID)\npipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\nprint(\"\u2705 Model loaded and ready.\")\n\n# === PROMPT BUILDER ===\ndef build_prompt(symptoms):\n    symptom_list = ', '.join(symptoms)\n    return f\"\"\"Write a short emergency call *monologue* in English, as if a distressed civilian is calling a medical emergency center.\n\nThe caller should describe an emergency situation involving the following symptoms:\n{symptom_list}\n\nThe monologue should be realistic and emotional, possibly showing confusion, panic, hesitation, informal language, or repetitions. The speaker should NOT mention the name of any disease \u2013 only describe the symptoms directly or indirectly.\n\nFocus on natural speech: disorganized phrasing, missing words, fear, or uncertainty are welcome. This should feel like a real person under pressure calling for help.\n\nOnly include the caller\u2019s words \u2013 do NOT include any dispatcher responses or questions.\n\nThis output will later be used for Text-to-Speech generation, so write only the caller\u2019s spoken text.\"\"\"\n\n# === GENERATION LOOP WITH MANUAL REVIEW ===\nall_calls = []\n\nfor disease in tqdm(symptom_matrix.index):\n    true_symptoms = symptom_matrix.loc[disease]\n    present_symptoms = [s for s in true_symptoms.index if true_symptoms[s]]\n    if not present_symptoms:\n        continue\n\n    for _ in range(NUM_CALLS_PER_DISEASE):\n        sampled = random.sample(present_symptoms, min(3, len(present_symptoms)))\n        prompt = build_prompt(sampled)\n\n        print(\"\\n\" + \"=\" * 80)\n        print(f\"\ud83e\ude7a Disease: {disease}\")\n        print(f\"\ud83e\uddfe Symptoms: {', '.join(sampled)}\")\n        print(\"-\" * 80)\n\n        try:\n            result = pipe(prompt, max_new_tokens=200, do_sample=True, temperature=0.9)[0][\"generated_text\"]\n            print(f\"\ud83d\udce4 Generated Monologue:\\n{result}\")\n        except Exception as e:\n            print(f\"\u274c Error: {e}\")\n            continue\n\n        # Manual approval\n        approve = input(\"\u2714\ufe0f Save this call? (y/n): \").strip().lower()\n        if approve != 'y':\n            print(\"\u23ed Skipping...\")\n            continue\n\n        all_calls.append({\n            \"disease\": disease,\n            \"symptoms_used\": \", \".join(sampled),\n            \"generated_call\": result\n        })\n\n# === SAVE OUTPUT ===\npd.DataFrame(all_calls).to_csv(OUTPUT_FILE, index=False)\nprint(f\"\\n\u2705 Saved {len(all_calls)} approved calls to {OUTPUT_FILE}\")\n"
        # Create a sandboxed globals dict; allow imports but prevent polluting our module globals
        g = {"__name__": "__main__"}
        g.update(self.extra_globals)
        exec(code, g, g)
        return SimpleNamespace(**g)  # return namespace with any artifacts the script produced
